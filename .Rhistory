}
})
# In tables with missing features, add empty features accordingly
#-------------------------------------------------------------------------------
DataSet <- DataSet %>%
imap(function(Table, tablename)
{
# Determine missing features
RequiredFeatureNames <- dplyr::filter(dsCCPhos::Meta.Features, TableName.Curated == tablename)$FeatureName.Curated
PresentFeatureNames <- names(Table)
MissingFeatures <- RequiredFeatureNames[!(RequiredFeatureNames %in% PresentFeatureNames)]
# If a table misses features, add empty columns accordingly
if (length(MissingFeatures) > 0)
{
ComplementedDataFrame <- Table %>%
mutate(!!!set_names(rep(list(NA_character_), length(MissingFeatures)), MissingFeatures))
return(ComplementedDataFrame)
} else {
return(Table)
}
})
#===============================================================================
# MODULE B)  Primary entry exclusion
#===============================================================================
#   1) Remove entries that are not linked to related tables
#   2) Remove entries in RDS with missing strictly obligatory features (determined in meta data / passed through Settings)
#   3) Remove duplicate entries
#   4) Remove entries that are not consistent with special trans-feature obligation rules (defined in meta data / passed through Settings)
#-------------------------------------------------------------------------------
#===============================================================================
# MONITORING: Count table entries
#===============================================================================
# Count entries in initial data.frames
CountEntries_Initial <- DataSet %>%
map_int(\(Table) ifelse (!is.null(nrow(Table)), nrow(Table), 0))
# By merging 'Patient' and 'Diagnosis', create auxiliary data frame containing all eligible combinations of PatientIDs and DiagnosisIDs
# Do NOT simply delete (pseudo-)duplicate entries (because different DiagnosisIDs of same patient and diagnosis can e.g. be related to different Histologies).
# Filter out any entry that has missings in features marked as obligatory in meta data (thereby also removing 'rogue'/unlinked patient or diagnosis entries because this way every patient needs to have at least one related diagnosis and vice versa)
DataSetRoot <- DataSet$Patient %>%
left_join(DataSet$Diagnosis, by = join_by(PatientID)) %>%
{   if (Settings$TableCleaning$Run == TRUE)
{
dsFreda::CleanTable(Table = .,
TableNameLookup = c("Diagnosis", "Patient"),
RemoveEmptyStrings = TRUE,
RemoveRedundantEntries = FALSE,
FeatureObligations = Settings$FeatureObligations)
} else {.}
} %>%
select(PatientID, DiagnosisID) %>%
distinct()
#===============================================================================
# - Loop through whole DataSet to only keep entries that belong to eligible 'root'
# - Remove entries that have missing values in strictly obligatory features (defined in meta data / passed as an argument)
# - Remove duplicate entries
# - Remove entries that are not consistent with special trans-feature obligation rules (defined in meta data / passed as an argument)
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
ProgressBar <- progress_bar$new(format = "Primary exclusion: Excluding ineligible table entries... [:bar] :percent in :elapsed  :spin",
total = length(DataSet), clear = FALSE, width = 100)
#-------------------------------------------------------------------------------
DataSet <- DataSet %>%
imap(function(Table, tablename)
{
try(ProgressBar$tick())
if (!(is.null(Table) | length(Table) == 0 | nrow(Table) == 0))
{
# Join current table with preselection of 'DataSetRoot'
if (all(c("PatientID", "DiagnosisID") %in% names(Table)))
{
Table <- DataSetRoot %>%
left_join(Table, by = join_by(PatientID, DiagnosisID))
} else {
Table <- DataSetRoot %>%
select(PatientID) %>%
distinct() %>%
left_join(Table, by = join_by(PatientID))
}
# Clean current table using auxiliary function dsFreda::CleanTable() (Can be optionally omitted)
if (Settings$TableCleaning$Run == TRUE)
{
Table <- Table %>%
dsFreda::CleanTable(TableNameLookup = tablename,
RemoveEmptyStrings = TRUE,
RemoveRedundantEntries = TRUE,
FeatureObligations = Settings$FeatureObligations)
}
return(Table)
} else {
return(Table)
}
})
try(ProgressBar$terminate())
#===============================================================================
# MONITORING: Count ineligible entries
#===============================================================================
# Count entries in data frames after primary exclusion
CountEntries_AfterPrimaryExclusion <- DataSet %>%
map_int(\(Table) ifelse (!is.null(nrow(Table)), nrow(Table), 0))
# Count excluded entries
CountExcludedEntries_Primary <- CountEntries_Initial - CountEntries_AfterPrimaryExclusion
# Print messages for live monitoring in local tests
for (i in 1:length(CountExcludedEntries_Primary))
{
Message <- paste0("Primary exclusion: Removed ", CountExcludedEntries_Primary[i], " ineligible entries from '", names(CountExcludedEntries_Primary)[i], "' table.")
cli::cat_bullet(Message, bullet = "info")
# Save messages in output object
Messages$ExcludedEntries_Primary <- c(Messages$ExcludedEntries_Primary,
info = Message)
}
cat("\n")
#===============================================================================
# MODULE C)  Table Normalization
#===============================================================================
#   - Perform procedures like 'split and expand' where necessary (as determined by settings / meta data)
#-------------------------------------------------------------------------------
if (Settings$TableNormalization$Run == TRUE)
{
#-----------------------------------------------------------------------------
ProgressBar <- progress_bar$new(format = "Table Normalization... [:bar] :percent in :elapsed  :spin",
total = length(DataSet), clear = FALSE, width = 100)
#-----------------------------------------------------------------------------
DataSet <- DataSet %>%
imap(function(Table, tablename)
{
try(ProgressBar$tick())
Table <- Table %>%
dsFreda::NormalizeTable(TableName = tablename,
RuleSet = Settings$TableNormalization$RuleSet,
RuleSet.Profile = Settings$TableNormalization$RuleSet.Profile)
return(Table)
})
try(ProgressBar$terminate())
}
#===============================================================================
# MODULE D)  Data Harmonization / Transformation
#===============================================================================
#   1) Definition of features to monitor during Transformation
#   2) Tracking of raw feature values
#   3) Data harmonization (correctional transformation)
#   4) Tracking of harmonized feature values
#   5) Data recoding and formatting
#   6) Tracking of recoded / formatted feature values
#   7) Finalize transformation of data
#        - Removing of ineligible values
#        - Optional conversion to factor
#   8) Tracking of finalized feature values
#   9) Compilation of monitor objects for reporting
#-------------------------------------------------------------------------------
#===============================================================================
# Module D 1)  Definition of tracked features and their sets of eligible values
#===============================================================================
#     - Create meta data on eligible value sets of features to be tracked / monitored during curation process
#     - Element object syntax: List of vectors
#         - Vector names = Name of feature to be monitored during Curation (Transformation)
#         - Vector values = Set of eligible values obtained from meta data / passed rule set
#     - If a feature should be monitored but has no specific set of eligible values, set it NULL
#-------------------------------------------------------------------------------
ls_MonitorMetaData <- names(DataSet) %>%
map(function(tablename)
{
vc_FeaturesToTrack <- Settings$FeatureTracking$RuleSet %>%
rename(IsTracked = all_of(Settings$FeatureTracking$RuleSet.Profile)) %>%      # Renaming feature based on passed argument
filter(Table == tablename,
IsTracked == TRUE) %>%
pull(Feature)
ls_EligibleValues <- vc_FeaturesToTrack %>%
map(function(featurename)
{
Values <- dsCCPhos::Meta.Values %>%
filter(Table == tablename,
Feature == featurename) %>%
select(Value.Raw,
Value.Curated)
if (nrow(Values) == 0) { return(NULL) } else { return(Values) }
}) %>%
set_names(vc_FeaturesToTrack)
}) %>%
set_names(names(DataSet))
#===============================================================================
# Module D 2)  Track feature values of raw data
#===============================================================================
#   - Get unique raw values and their frequencies for monitoring
#   - Copy values of monitored features and mark them with TrackID that has correspondent in actually processed data frames
#-------------------------------------------------------------------------------
# Check if object names in DataSet and ls_MonitorMetaData are identical to avoid incorrect mapping
if (all(names(DataSet) == names(ls_MonitorMetaData)))
{
# Initiate list of data frames containing transformation tracks
# First step: Store copied raw values of monitored features and mark them with "TrackID" to track them along transformation process
ls_TransformationTracks <- map2(.x = DataSet,
.y = ls_MonitorMetaData,
.f = function(DataFrame, MonitorMetaData)
{
if (purrr::is_empty(MonitorMetaData) == FALSE)
{
DataFrame %>%
select(names(MonitorMetaData)) %>%
rename_with(.fn = ~ str_c(., "__Raw"),   # Two underscores for later use in pivot_longer()
.cols = everything()) %>%
mutate(TrackID = row_number(), .before = 1)   # Create TrackID to enable correct mapping and further processing
}
else { return(data.frame()) }
})
ls_ValueCounts_Raw <- map2(.x = DataSet,
.y = ls_MonitorMetaData,
.f = function(DataFrame, MonitorMetaData)
{
DataFrame %>%
dsFreda::TrackValueCounts(FeatureNames = names(MonitorMetaData),
TransformationStage = "Raw") %>%
select(Feature,
Value,
Frequency) %>%
rename(Value.Raw = Value,
Count.Raw = Frequency)
})
} else {
stop("Internal error: Object names in DataSet and ls_MonitorMetaData must be identical and in the same order.")
}
#===============================================================================
# Module D 3)  Data Harmonization (correctional transformation)
#===============================================================================
#   Step-wise approach incorporating the following methods (controlled by meta data / arguments)
#   1. Transformative expressions
#   2. Dictionary look-up
#   3. Fuzzy String Matching
#-------------------------------------------------------------------------------
Table <- DataSet$Staging
tablename <- "Staging"
Table <- Table %>% mutate(TrackID = row_number())      # Enables tracking of transformation (see above)
if (Settings$DataHarmonization$Run == TRUE)      # The check is placed here and not before the mapping function so that the 'TrackID' is appended regardless (see above)
{
HarmonizationProcess <- Settings$DataHarmonization$Process %>%
filter(Profile == Settings$DataHarmonization$Process.Profile,
Table == tablename,
RunHarmonization == TRUE) %>%
arrange(HarmonizationOrder)      # Defines the order in which features within a table are being harmonized (this can be relevant in transformative espressions that contain inter-feature dependencies)
for (featurename in HarmonizationProcess$Feature)
{
Methods <- Settings$DataHarmonization$Process %>%
filter(Table == tablename,
Feature == featurename) %>%
as.list()
EligibleValueSet <- dsCCPhos::Meta.Values %>%
filter(Table == tablename,
Feature == featurename) %>%
pull(Value.Curated)
TransformativeExpressions <- Settings$DataHarmonization$TransformativeExpressions %>%
filter(Table == tablename,
Feature == featurename)
Dictionary <- Settings$DataHarmonization$Dictionary %>%
filter(Table == tablename,
Feature == featurename) %>%
pull(var = NewValue,
name = LookupValue)
FuzzyStringMatching <- Settings$DataHarmonization$FuzzyStringMatching %>%
filter(Table == tablename,
Feature == featurename) %>%
as.list()
Table <- Table %>%
mutate(across(all_of(featurename),
~ dsFreda::HarmonizeFeature(Feature = .x,
FeatureName = featurename,
ContextDataFrame = Table,
Methods = Methods,
EligibleValueSet = EligibleValueSet,
TransformativeExpressions = TransformativeExpressions,
Dictionary = Dictionary,
FuzzyStringMatching = FuzzyStringMatching)))
}
}
rlang::last_trace()
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
library(dplyr)
library(dsCCPhos)
library(dsFreda)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load CCP test data as raw data set
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#RawDataSet <- readRDS(file = "./Development/Data/RealData/CCPRealData_Frankfurt.rds")
#OldTestData <- readRDS(file = "./Development/Data/TestData/OldTestData/CCPTestData.rds")
RawDataSet <- readRDS(file = "./Development/Data/TestData/CCPTestData.rds")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Rename tables of RawDataSet (the names are also changed when tables are being loaded into R server sessions)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
vc_Lookup <- paste0("RDS.", dsCCPhos::Meta.Tables$TableName.Curated)
names(vc_Lookup) <- dsCCPhos::Meta.Tables$TableName.Raw
names(RawDataSet) <- sapply(names(RawDataSet),
function(TableName) { vc_Lookup[TableName] })
RDSTableCheck <- dsFreda::GetDataSetCheckDS(DataSetName.S = "RawDataSet",
Module.S = "CCP",
TransformationStage.S = "Raw")
rlang::last_trace()
devtools::load_all(".")
library(dplyr)
library(dsCCPhos)
library(dsFreda)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load CCP test data as raw data set
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#RawDataSet <- readRDS(file = "./Development/Data/RealData/CCPRealData_Frankfurt.rds")
#OldTestData <- readRDS(file = "./Development/Data/TestData/OldTestData/CCPTestData.rds")
RawDataSet <- readRDS(file = "./Development/Data/TestData/CCPTestData.rds")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Rename tables of RawDataSet (the names are also changed when tables are being loaded into R server sessions)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
vc_Lookup <- paste0("RDS.", dsCCPhos::Meta.Tables$TableName.Curated)
names(vc_Lookup) <- dsCCPhos::Meta.Tables$TableName.Raw
names(RawDataSet) <- sapply(names(RawDataSet),
function(TableName) { vc_Lookup[TableName] })
RDSTableCheck <- dsFreda::GetDataSetCheckDS(DataSetName.S = "RawDataSet",
Module.S = "CCP",
TransformationStage.S = "Raw")
rlang::last_trace()
devtools::load_all(".")
library(dplyr)
library(dsCCPhos)
library(dsFreda)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load CCP test data as raw data set
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#RawDataSet <- readRDS(file = "./Development/Data/RealData/CCPRealData_Frankfurt.rds")
#OldTestData <- readRDS(file = "./Development/Data/TestData/OldTestData/CCPTestData.rds")
RawDataSet <- readRDS(file = "./Development/Data/TestData/CCPTestData.rds")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Rename tables of RawDataSet (the names are also changed when tables are being loaded into R server sessions)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
vc_Lookup <- paste0("RDS.", dsCCPhos::Meta.Tables$TableName.Curated)
names(vc_Lookup) <- dsCCPhos::Meta.Tables$TableName.Raw
names(RawDataSet) <- sapply(names(RawDataSet),
function(TableName) { vc_Lookup[TableName] })
RDSTableCheck <- dsFreda::GetDataSetCheckDS(DataSetName.S = "RawDataSet",
Module.S = "CCP",
TransformationStage.S = "Raw")
rlang::last_trace()
library(dplyr)
library(readxl)
library(usethis)
ExcelFilePath <- "./Development/Data/MetaData/MetaDataCCPhos.xlsx"
Sheetnames <- c("Meta.Tables",
"Meta.Features",
"Meta.Values",
"Proc.EventFeatures",
"Proc.TableNormalization",
"Set.FeatureObligations",
"Set.FeatureTracking",
"Set.DataHarmonization",
"Set.TransformativeExpressions",
"Set.Dictionary",
"Set.FuzzyStringMatching",
"Set.DiagnosisRedundancy",
"Set.DiagnosisAssociation")
for (sheetname in Sheetnames)
{
Table <- read_excel(path = ExcelFilePath,
sheet = sheetname,
skip = 2,
col_types = "text")
ColumnTypes <- read_excel(path = ExcelFilePath,
sheet = sheetname,
range = cell_rows(2),
col_names = colnames(Table)) %>%
tidyr::pivot_longer(everything(),
names_to = "Column",
values_to = "Type")
if (nrow(ColumnTypes) > 0)
{
for (i in 1:nrow(ColumnTypes))
{
Table <- Table %>%
mutate(across(all_of(ColumnTypes$Column[i]),
~ dsFreda::FormatData(.x, ColumnTypes$Type[i])))
}
}
assign(x = sheetname,
value = Table)
# Save data in .rda-file and make it part of the package
do.call(use_data, list(as.name(sheetname), overwrite = TRUE))
}
devtools::load_all(".")
devtools::load_all(".")
library(dplyr)
library(readxl)
library(usethis)
library(dplyr)
library(readxl)
library(usethis)
ExcelFilePath <- "./Development/Data/MetaData/MetaDataCCPhos.xlsx"
Sheetnames <- c("Meta.Tables",
"Meta.Features",
"Meta.Values",
"Proc.EventFeatures",
"Proc.TableNormalization",
"Set.FeatureObligations",
"Set.FeatureTracking",
"Set.DataHarmonization",
"Set.TransformativeExpressions",
"Set.Dictionary",
"Set.FuzzyStringMatching",
"Set.DiagnosisRedundancy",
"Set.DiagnosisAssociation")
for (sheetname in Sheetnames)
{
Table <- read_excel(path = ExcelFilePath,
sheet = sheetname,
skip = 2,
col_types = "text")
ColumnTypes <- read_excel(path = ExcelFilePath,
sheet = sheetname,
range = cell_rows(2),
col_names = colnames(Table)) %>%
tidyr::pivot_longer(everything(),
names_to = "Column",
values_to = "Type")
if (nrow(ColumnTypes) > 0)
{
for (i in 1:nrow(ColumnTypes))
{
Table <- Table %>%
mutate(across(all_of(ColumnTypes$Column[i]),
~ dsFreda::FormatData(.x, ColumnTypes$Type[i])))
}
}
assign(x = sheetname,
value = Table)
# Save data in .rda-file and make it part of the package
do.call(use_data, list(as.name(sheetname), overwrite = TRUE))
}
devtools::load_all(".")
library(dplyr)
library(readxl)
library(usethis)
ExcelFilePath <- "./Development/Data/MetaData/MetaDataCCPhos.xlsx"
Sheetnames <- c("Meta.Tables",
"Meta.Features",
"Meta.Values",
"Proc.EventFeatures",
"Proc.TableNormalization",
"Set.FeatureObligations",
"Set.FeatureTracking",
"Set.DataHarmonization",
"Set.TransformativeExpressions",
"Set.Dictionary",
"Set.FuzzyStringMatching",
"Set.DiagnosisRedundancy",
"Set.DiagnosisAssociation")
for (sheetname in Sheetnames)
{
Table <- read_excel(path = ExcelFilePath,
sheet = sheetname,
skip = 2,
col_types = "text")
ColumnTypes <- read_excel(path = ExcelFilePath,
sheet = sheetname,
range = cell_rows(2),
col_names = colnames(Table)) %>%
tidyr::pivot_longer(everything(),
names_to = "Column",
values_to = "Type")
if (nrow(ColumnTypes) > 0)
{
for (i in 1:nrow(ColumnTypes))
{
Table <- Table %>%
mutate(across(all_of(ColumnTypes$Column[i]),
~ dsFreda::FormatData(.x, ColumnTypes$Type[i])))
}
}
assign(x = sheetname,
value = Table)
# Save data in .rda-file and make it part of the package
do.call(use_data, list(as.name(sheetname), overwrite = TRUE))
}
?as.character
library(devtools)
use_package_doc()
devtools::load_all(".")
library(devtools)
library(devtools)
# Use the %>%-operator in this package (not enough to import dplyr)
#-------------------------------------------------------------------------------
use_pipe(export = FALSE)
use_package("assertthat")
use_package("cli")
use_package("dplyr")
# use_dev_package("dsFreda", remote = "BastianReiter/dsFreda")
use_package("lubridate")
# use_package("MatchIt")
use_package("resourcer", type = "Suggests")
use_package("rlang")
use_package("stats")
use_package("stringr")
use_package("tibble")
use_package("tidyr")
devtools::load_all(".")
# Use functions from external packages
#-------------------------------------------------------------------------------
# use_import_from("stringdist", "stringdist")
use_import_from("progress", "progress_bar")
library(devtools)
# Use functions from external packages
#-------------------------------------------------------------------------------
# use_import_from("stringdist", "stringdist")
use_import_from("progress", "progress_bar")
?difftime
?time_length
?MatchIt::match.data()
devtools::load_all(".")
