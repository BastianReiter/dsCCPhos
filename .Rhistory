RawData <- RawDataSet$RDS_SystemicTherapy$systemische_therapie_substanzen
RawData
?str_split
View(RawData)
Test <- str_split(RawData, ",")
unlist(Test)
Test <- unlist(str_split(RawData, "[,/]"))
Test <- RawData %>%
str_split(., "[,/]")
Test <- RawData %>%
str_split(., "[,/]") %>%
unlist()
Test <- RawData %>%
str_split("[,/]") %>%
unlist()
Test <- RawData %>%
str_split("[,/]") %>%
unlist() %>%
unique()
View(as.data.frame(Test))
ATCCodes <- TinkerLab::ATCCodes
ATCCodes <- TinkerLab::ATCCodes %>%
distinct()
View(ATCCodes)
ATCCodes <- TinkerLab::ATCCodes %>%
distinct() %>%
filter(str_starts(ATCCode, pattern = "L"))
Substances <- TinkerLab::ATCCodes %>%
distinct() %>%
filter(str_starts(ATCCode, pattern = "L")) %>%
pull(NameGerman)
Substances <- TinkerLab::ATCCodes %>%
distinct() %>%
filter(str_starts(ATCCode, pattern = "L")) %>%
arrange(NameGerman) %>%
pull(NameGerman)
TestData <- RawData %>%
str_split("[,/]") %>%
unlist() %>%
unique()
View(as.data.frame(TestData))
?itoken
library(text2vec)
Iterator <- itoken(iterable = TestData,
tokenizer = GetNGrams(),
progressbar = FALSE)
?create_vocabulary
Vocabulary <- create_vocabulary(it = Iterator)
?itoke
?itoken
Iterator <- itoken(iterable = TestData,
tokenizer = word_tokenizer,
n_chunks = 3,
progressbar = FALSE)
Vocabulary <- create_vocabulary(it = Iterator)
View(Vocabulary)
?vocab_vectorizer
Vectorizer <- vocab_vectorizer(Vocabulary)
?create_dtm
DTM <- create_dtm(it = Iterator,
vectorizer = Vectorizer)
Vectorizer
?sample.split
install.packages(caTools)
install.packages("caTools")
library(caTools)
TrainingData <- sample.split(TestData, SplitRatio = 0.7)
TrainingData
SplitIndicator <- sample.split(TestData, SplitRatio = 0.7)
TrainingData <- RawData[SplitIndicator]
PredictData <- RawData[!SplitIndicator]
PredictData <- TestData[!SplitIndicator]
TrainingData <- TestData[SplitIndicator]
PredictData <- TestData[!SplitIndicator]
TrainingData
Iterator <- itoken(iterable = TrainingData,
tokenizer = word_tokenizer,
n_chunks = 3,
progressbar = FALSE)
Vocabulary <- create_vocabulary(it = Iterator)
Vectorizer <- vocab_vectorizer(Vocabulary)
Iterator_Training <- itoken(iterable = TrainingData,
tokenizer = word_tokenizer,
n_chunks = 3,
progressbar = FALSE)
Vocabulary <- create_vocabulary(it = Iterator)
Vectorizer <- vocab_vectorizer(Vocabulary)
Iterator_Training <- itoken(iterable = TrainingData,
tokenizer = word_tokenizer,
n_chunks = 3,
progressbar = FALSE)
Vocabulary <- create_vocabulary(it = Iterator_Training)
Vectorizer <- vocab_vectorizer(Vocabulary)
Iterator.Training <- itoken(iterable = TrainingData,
tokenizer = word_tokenizer,
n_chunks = 3,
progressbar = FALSE)
Vocabulary <- create_vocabulary(it = Iterator.Training)
Vectorizer <- vocab_vectorizer(Vocabulary)
DTM.Training <- create_dtm(it = Iterator.Training,
vectorizer = Vectorizer)
PredictionData <- TestData[!SplitIndicator]
Iterator.Prediction <- itoken(iterable = PredictionData,
tokenizer = word_tokenizer,
n_chunks = 3,
progressbar = FALSE)
Vocabulary <- create_vocabulary(it = Iterator.Training)
Vectorizer <- vocab_vectorizer(Vocabulary)
DTM.Prediction <- create_dtm(it = Iterator.Prediction,
vectorizer = Vectorizer)
library(e1071)
Substances
library(TinkerLab)
library(caTools)
library(e1071)
library(text2vec)
library(TinkerLab)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load CCP test data as raw data set
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#RawDataSet <- readRDS(file = "./Development/Data/RealData/CCPRealData_Frankfurt.rds")
#OldTestData <- readRDS(file = "./Development/Data/TestData/OldTestData/CCPTestData.rds")
RawDataSet <- readRDS(file = "./Development/Data/TestData/CCPTestData.rds")
RawData <- RawDataSet$RDS_SystemicTherapy$systemische_therapie_substanzen
TestData <- RawData %>%
str_split("[,/]") %>%
unlist() %>%
unique()
library(caTools)
library(dplyr)
library(e1071)
library(text2vec)
library(TinkerLab)
RawDataSet <- readRDS(file = "./Development/Data/TestData/CCPTestData.rds")
RawData <- RawDataSet$RDS_SystemicTherapy$systemische_therapie_substanzen
TestData <- RawData %>%
str_split("[,/]") %>%
unlist() %>%
unique()
library(stringr)
TestData <- RawData %>%
str_split("[,/]") %>%
unlist() %>%
unique()
View(as.data.frame(TestData))
RawDataSet <- readRDS(file = "../Data/TestData/CCPTestData.rds")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load CCP test data as raw data set
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#RawDataSet <- readRDS(file = "./Development/Data/RealData/CCPRealData_Frankfurt.rds")
#OldTestData <- readRDS(file = "./Development/Data/TestData/OldTestData/CCPTestData.rds")
RawDataSet <- readRDS(file = "./Development/Data/TestData/CCPTestData.rds")
RawDataSet <- readRDS(file = "./Development/Data/TestData/CCPTestData.rds")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Rename tables of RawDataSet (the names are also changed when tables are being loaded into R server sessions)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
vc_Lookup <- paste0("RDS_", dsCCPhos::Meta_Tables$TableName_Curated)
names(vc_Lookup) <- dsCCPhos::Meta_Tables$TableName_Raw
names(RawDataSet) <- sapply(names(RawDataSet),
function(TableName) { vc_Lookup[TableName] })
RawData <- RawDataSet$RDS_SystemicTherapy$systemische_therapie_substanzen
TestData <- RawData %>%
str_split("[,/]") %>%
unlist() %>%
unique()
View(as.data.frame(TestData))
Substances <- TinkerLab::ATCCodes %>%
distinct() %>%
filter(str_starts(ATCCode, pattern = "L")) %>%
arrange(NameGerman) %>%
pull(NameGerman)
library(dsCCPhos)
library(dplyr)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load CCP test data as raw data set
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#RawDataSet <- readRDS(file = "./Development/Data/RealData/CCPRealData_Frankfurt.rds")
#OldTestData <- readRDS(file = "./Development/Data/TestData/OldTestData/CCPTestData.rds")
RawDataSet <- readRDS(file = "./Development/Data/TestData/CCPTestData.rds")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Rename tables of RawDataSet (the names are also changed when tables are being loaded into R server sessions)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
vc_Lookup <- paste0("RDS_", dsCCPhos::Meta_Tables$TableName_Curated)
names(vc_Lookup) <- dsCCPhos::Meta_Tables$TableName_Raw
names(RawDataSet) <- sapply(names(RawDataSet),
function(TableName) { vc_Lookup[TableName] })
library(caTools)
library(dplyr)
library(e1071)
library(stringr)
library(text2vec)
library(TinkerLab)
RawData <- RawDataSet$RDS_SystemicTherapy$systemische_therapie_substanzen
TestData <- RawData %>%
str_split("[,/]") %>%
unlist() %>%
unique()
View(as.data.frame(TestData))
Substances <- TinkerLab::ATCCodes %>%
distinct() %>%
filter(str_starts(ATCCode, pattern = "L")) %>%
arrange(NameGerman) %>%
pull(NameGerman)
Substances <- TinkerLab::ATCCodes %>%
distinct() %>%
filter(str_starts(ATCCode, pattern = "L")) %>%
arrange(NameGerman) %>%
pull(NameGerman)
DirtyData <- TinkerLab::MakeDirty(Substances)
rlang::last_trace()
rlang::last_trace(drop = FALSE)
library(dsCCPhos)
library(dplyr)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load CCP test data as raw data set
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#RawDataSet <- readRDS(file = "./Development/Data/RealData/CCPRealData_Frankfurt.rds")
#OldTestData <- readRDS(file = "./Development/Data/TestData/OldTestData/CCPTestData.rds")
RawDataSet <- readRDS(file = "./Development/Data/TestData/CCPTestData.rds")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Rename tables of RawDataSet (the names are also changed when tables are being loaded into R server sessions)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
vc_Lookup <- paste0("RDS_", dsCCPhos::Meta_Tables$TableName_Curated)
names(vc_Lookup) <- dsCCPhos::Meta_Tables$TableName_Raw
names(RawDataSet) <- sapply(names(RawDataSet),
function(TableName) { vc_Lookup[TableName] })
library(caTools)
library(dplyr)
library(e1071)
library(stringr)
library(text2vec)
library(TinkerLab)
Substances <- TinkerLab::ATCCodes %>%
distinct() %>%
filter(str_starts(ATCCode, pattern = "L")) %>%
arrange(NameGerman) %>%
pull(NameGerman)
DirtyData <- TinkerLab::MakeDirty(Substances)
View(DirtyData)
TestData <- TinkerLab::MakeDirty(Substances)
CleanData <- TinkerLab::ATCCodes %>%
distinct() %>%
filter(str_starts(ATCCode, pattern = "L")) %>%
arrange(NameGerman) %>%
pull(NameGerman)
TestData <- TinkerLab::MakeDirty(CleanData)
View(TinkerLab::ATCCodes)
?sample.split
?tidyr::pivot_longer
TestData <- TinkerLab::MakeDirty(CleanData) %>%
select(-Dirty)
View(TestData)
library(tidyr)
TestData <- TinkerLab::MakeDirty(CleanData) %>%
select(-Dirty) %>%
pivot_longer(cols = !Original,
names_to = NULL,
values_to = Test)
TestData <- TinkerLab::MakeDirty(CleanData) %>%
select(-Dirty) %>%
pivot_longer(cols = !Original,
names_to = NULL,
values_to = "Test")
View(TestData)
TestData <- TinkerLab::MakeDirty(CleanData) %>%
select(-Dirty) %>%
pivot_longer(cols = !Original,
names_to = NULL,
values_to = "Dirty") %>%
rename(Clean = "Original")
View(TestData)
SplitIndicator <- sample.split(TestData, SplitRatio = 0.7)
TrainingData <- TestData[SplitIndicator]
PredictionData <- TestData[!SplitIndicator]
View(TrainingData)
View(PredictionData)
?sample.split
SplitIndicator <- sample.split(TestData$Dirty, SplitRatio = 0.7)
TrainingData <- TestData$Dirty[SplitIndicator]
PredictionData <- TestData$Dirty[!SplitIndicator]
TrainingData <- TestData$Dirty
Iterator.Training <- itoken(iterable = TrainingData,
tokenizer = word_tokenizer,
n_chunks = 3,
progressbar = FALSE)
TrainingData <- TinkerLab::MakeDirty(CleanData) %>%
select(-Dirty) %>%
pivot_longer(cols = !Original,
names_to = NULL,
values_to = "Dirty") %>%
pull(Dirty)
PredictionData <- TinkerLab::MakeDirty(CleanData) %>%
select(-Dirty) %>%
pivot_longer(cols = !Original,
names_to = NULL,
values_to = "Dirty") %>%
pull(Dirty)
CleanData <- TinkerLab::MakeDirty(CleanData) %>%
select(-Dirty) %>%
pivot_longer(cols = !Original,
names_to = NULL,
values_to = "Dirty") %>%
pull(Original)
Iterator.Training <- itoken(iterable = TrainingData,
tokenizer = word_tokenizer,
n_chunks = 3,
progressbar = FALSE)
Iterator.Prediction <- itoken(iterable = PredictionData,
tokenizer = word_tokenizer,
n_chunks = 3,
progressbar = FALSE)
Vocabulary <- create_vocabulary(it = Iterator.Training)
Vectorizer <- vocab_vectorizer(Vocabulary)
DTM.Training <- create_dtm(it = Iterator.Training,
vectorizer = Vectorizer)
DTM.Prediction <- create_dtm(it = Iterator.Prediction,
vectorizer = Vectorizer)
Model <- naiveBayes(x = as.matrix(DTM.Training),
y = CleanData)
Predictions <- predict(Model, as.matrix(DTM.Prediction))
Predictions
CleanData <- TinkerLab::MakeDirty(CleanData) %>%
select(-Dirty) %>%
pivot_longer(cols = !Original,
names_to = NULL,
values_to = "Dirty")
View(CleanData)
Test <- CleanData %>%
rowwise() %>%
mutate(NGrams = GetNGrams(Original))
Test <- CleanData %>%
rowwise() %>%
mutate(NGrams = list(GetNGrams(Original)))
View(Test)
Test <- CleanData %>%
rowwise() %>%
mutate(NGrams = list(GetNGrams(Original, n = 3)))
?unnest
Test <- CleanData %>%
rowwise() %>%
mutate(NGrams = list(GetNGrams(Original, n = 3))) %>%
unnest(NGrams, keep_empty = TRUE)
Test <- CleanData %>%
rowwise() %>%
mutate(NGrams = list(GetNGrams(Original, n = 3))) %>%
ungrou() %>%
unnest(NGrams, keep_empty = TRUE)
Test <- CleanData %>%
rowwise() %>%
mutate(NGrams = list(GetNGrams(Original, n = 3))) %>%
ungroup() %>%
unnest(NGrams, keep_empty = TRUE)
Test <- CleanData %>%
rowwise() %>%
mutate(NGrams = list(GetNGrams(Original, n = 3))) %>%
ungroup() %>%
unnest(NGrams)
Test <- CleanData %>%
rowwise() %>%
mutate(NGrams = list(GetNGrams(Original, n = 3))) %>%
ungroup() %>%
unnest()
Test <- CleanData %>%
rowwise() %>%
mutate(NGrams = list(GetNGrams(Original, n = 3))) %>%
ungroup() %>%
unnest(c(NGrams))
?unnest_wider
Test <- CleanData %>%
rowwise() %>%
mutate(NGrams = list(GetNGrams(Original, n = 3))) %>%
ungroup() %>%
unnest_wider(NGrams)
Test <- CleanData %>%
rowwise() %>%
mutate(NGrams = list(GetNGrams(Original, n = 3))) %>%
ungroup() %>%
unnest_wider(NGrams, names_sep = "Tok")
View(Test)
Test <- CleanData %>%
rowwise() %>%
mutate(Token = list(GetNGrams(Original, n = 3))) %>%
ungroup() %>%
unnest_wider(Token, names_sep = "") %>%
select(Original,
all_of(paste0("Token", 1:10)))
?scale
Classifier <- naiveBayes(Original ~ ., data = Test)
Classifier
CleanData <- TinkerLab::ATCCodes %>%
distinct() %>%
filter(str_starts(ATCCode, pattern = "L")) %>%
arrange(NameGerman) %>%
pull(NameGerman)
TestData <- TinkerLab::MakeDirty(CleanData) %>%
select(-Dirty) %>%
pivot_longer(cols = !Original,
names_to = NULL,
values_to = "Dirty")
TokenizedData <- TestData %>%
rowwise() %>%
mutate(Token = list(GetNGrams(Original, n = 3))) %>%
ungroup() %>%
unnest_wider(Token, names_sep = "") %>%
select(Original,
all_of(paste0("Token", 1:10)))   # Only take first 10 n-grams into account
SplitIndicator <- sample.split(TokenizedData, SplitRatio = 0.7)
SplitIndicator <- sample.split(TokenizedData, SplitRatio = 0.7)
TrainingData <- subset(TokenizedData, SplitIndicator == TRUE)
?sample.split
SplitIndicator <- sample.split(TokenizedData$Original, SplitRatio = 0.7)
TrainingData <- subset(TokenizedData, SplitIndicator == TRUE)
PredictionData <- subset(TokenizedData, SplitIndicator == FALSE)
Classifier <- naiveBayes(Original ~ ., data = TrainingData)
View(PredictionData)
Predictions <- predict(Classifier, newdata = PredictionData)
ConfusionMatrix <- table(PredictionData$Original, Predictions)
?confusionMatrix
library(caret)
install.packages("caret")
ConfusionMatrix.Table <- table(PredictionData$Original, Predictions)
library(caret)
confusionMatrix(ConfusionMatrix.Table)
ConfusionMatrix <- confusionMatrix(ConfusionMatrix.Table)
ConfusionMatrix$table
View(ConfusionMatrix$table)
ConfusionMatrix$positive
ConfusionMatrix$overall
ConfusionMatrix$byClass
ConfusionMatrix$mode
ConfusionMatrix$dots
?confusionMatrix
Predictions
View(DirtyData)
devtools::load_all(".")
library(dsCCPhos)
library(dplyr)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Load CCP test data as raw data set
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#RawDataSet <- readRDS(file = "./Development/Data/RealData/CCPRealData_Frankfurt.rds")
#OldTestData <- readRDS(file = "./Development/Data/TestData/OldTestData/CCPTestData.rds")
RawDataSet <- readRDS(file = "./Development/Data/TestData/CCPTestData.rds")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Rename tables of RawDataSet (the names are also changed when tables are being loaded into R server sessions)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
vc_Lookup <- paste0("RDS_", dsCCPhos::Meta_Tables$TableName_Curated)
names(vc_Lookup) <- dsCCPhos::Meta_Tables$TableName_Raw
names(RawDataSet) <- sapply(names(RawDataSet),
function(TableName) { vc_Lookup[TableName] })
RDSTableCheck <- CheckDataSetDS(DataSetName.S = "RawDataSet",
AssumeCCPDataSet.S = TRUE)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Curate data
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
CurationOutput <- dsCCPhos::CurateDataDS(RawDataSetName.S = "RawDataSet",
Settings.S = list(DataHarmonization = list(Run = TRUE,
Profile = "Default"),
FeatureObligations = list(Profile = "Default"),
FeatureTracking = list(Profile = "Default"),
TableCleaning = list(Run = TRUE)))
library(readxl)
library(usethis)
Meta_Tables <- read_excel(path = "./Development/Data/MetaData/MetaDataCCPhos.xlsx",
sheet = "Tables")
# Save data in .rda-file and make it part of package
use_data(Meta_Tables, overwrite = TRUE)
Meta_Features <- read_excel(path = "./Development/Data/MetaData/MetaDataCCPhos.xlsx",
sheet = "Features")
# Save data in .rda-file and make it part of package
use_data(Meta_Features, overwrite = TRUE)
Meta_Values <- read_excel(path = "./Development/Data/MetaData/MetaDataCCPhos.xlsx",
sheet = "Values",
skip = 1)
# Save data in .rda-file and make it part of package
use_data(Meta_Values, overwrite = TRUE)
Meta_EventFeatures <- read_excel(path = "./Development/Data/MetaData/MetaDataCCPhos.xlsx",
sheet = "EventFeatures")
# Save data in .rda-file and make it part of package
use_data(Meta_EventFeatures, overwrite = TRUE)
Meta_FeatureObligations <- read_excel(path = "./Development/Data/MetaData/MetaDataCCPhos.xlsx",
sheet = "FeatureObligations",
skip = 1)
# Save data in .rda-file and make it part of package
use_data(Meta_FeatureObligations, overwrite = TRUE)
Meta_FeatureTracking <- read_excel(path = "./Development/Data/MetaData/MetaDataCCPhos.xlsx",
sheet = "FeatureTracking",
skip = 1)
# Save data in .rda-file and make it part of package
use_data(Meta_FeatureTracking, overwrite = TRUE)
Meta_DataHarmonization <- read_excel(path = "./Development/Data/MetaData/MetaDataCCPhos.xlsx",
sheet = "DataHarmonizationRules",
skip = 1)
Meta_DataHarmonizationRules <- read_excel(path = "./Development/Data/MetaData/MetaDataCCPhos.xlsx",
sheet = "DataHarmonizationRules",
skip = 1)
# Save data in .rda-file and make it part of package
use_data(Meta_DataHarmonizationRules, overwrite = TRUE)
devtools::load_all(".")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Curate data
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
CurationOutput <- dsCCPhos::CurateDataDS(RawDataSetName.S = "RawDataSet",
Settings.S = list(DataHarmonization = list(Run = TRUE,
Profile = "Default"),
FeatureObligations = list(Profile = "Default"),
FeatureTracking = list(Profile = "Default"),
TableCleaning = list(Run = TRUE)))
CuratedDataSet <- CurationOutput$CuratedDataSet
CDSTableCheck <- CheckDataSetDS(DataSetName.S = "CuratedDataSet",
AssumeCCPDataSet.S = TRUE)
AugmentationOutput <- dsCCPhos::AugmentDataDS(CuratedDataSetName.S = "CuratedDataSet")
